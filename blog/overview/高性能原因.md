# 高性能原因浅析
Redis作为开源No-SQL技术的热门代表，在互联网公司里得到广泛的应用，其中一个最重要的原因是高性能,尤其是在秒杀/session缓存等场景，那么Redis自身是如何实现高性能呢？

要回答这个问题，就需要研读Redis源代码，从中理解Redis的设计思想与实现技巧，同时也提升自身的技术能力。

笔者这里从宏观层面解释一下Redis高性能的原因。

## Redis整体介绍
Redis从问世之初就以高性能横行天下，究其整体来看，采用异步模型才是其最核心的原因。

这里先解释一下笔者所说异步模型的含义。有时候我们会遇到需要同时做多件事的场景，一般有两种解决方案，一种是并行，即有多个worker并行处理不同的事情，在多核cpu服务器上多进程/多线程执行，将某些可能阻塞主流程执行的任务交由后台进程/线程慢慢执行，而主流程继续执行。当后台执行完毕后再通知主流程进行一些收尾工作。另一种是并发，即时间片轮转执行不同任务，单一时间片里只执行一项任务，下一时间片执行另一项任务。

Redis异步模型就是指代上述两种方式，Redis将一些可能阻塞主流程的任务交由后台进程/线程异步执行，例如：数据持久化、删除大容量key，删除磁盘文件等。另一方面，Redis又会将多种实时却耗时任务并发执行，例如：TCP套接字的多路复用、定时过期数据的清理、集群节点之间的握手连接等。

有一种说法，Redis是单进程/单线程架构，避免了锁的使用，进而实现的高性能。这种说法不太准确。的确Redis的核心业务是以单进程/单线程执行，例如：API的请求应答；定时失效数据的淘汰等关键任务。但是随着Redis的逐步演进，Redis也在利用CPU多核硬件优势。其实从很早的版本开始，一直到目前的v5.0.5里面，Redis里有很多支援保障性的任务是通过多进程/多线程实现的，这其中也涉及到了信号/互斥锁/条件变量等同步机制。如果仅仅是通过单进程/单线程这单一方案是无法实现高性能。

单进程/单线程有其自身的优势，例如：无需锁等同步机制；天然支持原子性；对编码友好；易于调试定位问题等。但是劣势也是很明显，例如：无法发挥多核的优势；阻塞式函数的调用会极大的影响性能等。

Redis的作者充分挖掘各类技术方案的特点，优势结合，很好的利用单进程/单线程的优势，同时采用异步模型以解决其劣势。当然也不拘泥于此，也适时的引入多进程/多线程来解决某些特别需求，整体上有一种"博采众家之长为我所用"的感觉。

如下会从几个层面概括性的介绍Redis是如何组合使用这些技术方案。

## 网络通信层面
Redis使用TCP/IP网络连接，内部支持多种平台下的多路复用技术，例如在Linux平台下使用epoll方案，并采用水平触发工作方式。在面对网络数据传输这一“慢速”场景下，将所有套接字的属性设置为Non-Block模式，只有在内核有可读写数据时应用层才会进行实际的读写操作，空闲时让出CPU进行其他已就位的操作。

这里提两点Redis的编码小细节：

- 我们在编写服务端代码时，通常会将监听套接字置为Non-Block模式，并加入到多路复用函数里，当有新TCP连接完成了3次握手过程后变为可读事件等待应用层`accept()`获取。
<br>这个方式基本上是多路复用的标准使用方式。而Redis在使用时更进一步的考虑了如何应对一批客户端在短时间内集中发起TCP连接。其实这个是有实际场景需求，因为在实际项目中，Redis通常作为缓存or数据库使用，调用方为保证服务的高可用，往往会采用连接池的方式维持一批与Redis的长连接，再叠加多节点负载均衡机制的考虑，当有调用方应用重启or网络中断重连时，服务端的确会有大批量的已经完成3次握手的新连接短时间集中等待`accept()`的情况发生。Redis服务端这里需要及时处理新连接以便双方进入较为“慢速”的数据传输过程，同时也不能因为集中处理这批新连接而阻塞其他任务的执行。
<br>Redis采用的方式是轮番批量`accept()`，每轮至多处理1000个新连接，当达到此上限时，主动停止，让出CPU，等待下一轮的多路复用可读事件通知。

- 集群模式下，Redis主备节点之间因复制数据需要，会由备节点主动发起建立与主节点的TCP长连接，备节点使用Non-Block模式下的`connect()`方式。我们知道`connect()`方法会激活内核进行TCP 3次握手，而如果服务端未及时处理时，主动发起方的内核层面会尝试多次直至建立成功or超时，也就是说`connect()`可能会阻塞很久。

  > If the client TCP receives no response to its SYN segment, ETIMEDOUT is returned. 4.4BSD, for example, sends one SYN when connect is called, another 6 seconds later, and another 24 seconds later (p. 828 of TCPv2). If no response is received after a total of 75 seconds, the error is returned.<br>---《UNP》的connect函数章节

  为避免可能的阻塞情况，Redis使用了Non-Block模式的`connect()`方式，而此情况下`connect()`函数会立即返回-1，并将errno置为`EINPROGRESS`以标识此`connect()`激活的3次握手已在内核层面继续执行，目前只是暂未完毕。

  > When a TCP socket is set to nonblocking and then connect is called, connect returns immediately with an error of EINPROGRESS but the TCP three-way handshake continues. We then check for either a successful or unsuccessful completion of the connection's establishment using select.<br>---《UNP》的非阻塞connect章节

  那么非阻塞式的`connect()`终态结果如何获知呢？
  >Berkeley-derived implementations (and POSIX) have the following two rules regarding select and nonblocking connects:
  <br>1.When the connection completes successfully, the descriptor becomes writable(p. 531 of TCPv2).
  <br>2.When the connection establishment encounters an error, the descriptor becomes both readable and writable (p. 530 of TCPv2).<br>---《UNP》的非阻塞connect章节<span style="color:red;">[1]</span>

  >The process can then obtain the value of so_error by fetching the SO_ERROR socket option. The integer value returned by getsockopt is the pending error for the socket.The value of so_error is then reset to 0 by the kernel (p. 547 of TCPv2).<br>---《UNP》的通用socket属性章节<span style="color:red;">[1]</span>

  Redis就是采用通过epoll的读写事件通知，再调用`getsockopt()`的SO_ERROR方式获取`connect()`终态结果。这个异步方式很好的避免了阻塞情况。

## 数据持久化层面
数据持久化一直是数据库的重头戏，因为这关系到性能，更关系着数据安全。Redis可以通过配置选项作为纯内存缓存使用，也可以开启持久化功能，以满足不同的业务场景需求。

持久化必然会与磁盘打交道，相比于软件而言，硬件的演进是很漫长，从之前的机械式硬盘到固态盘，虽说IO性能有很大的提升，但是演进的速度是无法满足产品需求。所以Redis作者在数据持久化这一块做了大量的优化工作。

Redis持久化数据有两种格式<span style="color:red;">[2]</span>
1. RDB格式，猜测是`Redis Database`的缩写:)。简单来说就是内存的磁盘快照数据，由可配置的时间间隔+更新次数激活快照数据落盘，为二进制格式。
2. AOF格式，是`Append Only File`的缩写。从字母含义也可以看出是一种将新数据追加到文件尾部的方式，为文本格式。随着客户命令的频繁执行，这个格式必然会增大磁盘空间的消耗，另外带来更为严重的隐患：Redis重启时数据加载回放慢。所以Redis会定期自动进行一项Rewrite AOF的任务，以精简AOF文件内容。

之前提过，Redis核心业务是以单进程/单线程执行，而数据持久化又是一件非常耗时的任务。如何即能及时响应客户的读写操作，又能完成数据持久化呢？Redis作者在这一方面将异步模型以及各种IPC运用到令笔者叹为观止的程度，同时也能从中看到作者对操作系统尤其是文件操作有很深的理解。
- 运用`fork()`子进程将内存数据以RDB或者AOF格式保存到磁盘，而主进程继续响应客户读写操作。这里充分利用了多进程时的内存COW技术。Redis作者为此做了很多细致性的代码优化，可参考笔者分析的另一篇文章<span style="color:red;">[3]</span>
* 在子进程保存数据落盘时，主进程同时也在接收并执行客户的新命令。那么对于这些新命令是如何保证持久化的呢？
<br>其实对于RDB格式来说，子进程无需关注这些新命令，因为RDB是对某一刻（fork函数返回的那一刻）内存数据的磁盘快照，新命令会由下一轮的RDB来持久化。
<br>而对于AOF格式，Redis作者使用了无名管道`pipe()`的方式，将新命令数据从主进程发送给子进程，同时结合异步方式，主进程里有专用的发送缓冲链表记录待发送的新命令，并且会在管道发送句柄可写事件通知时才会发送尽可能多的数据。子进程里也有专用的接收缓冲区，而且是在子进程每完成10K字节的AOF数据落盘时，从管道接收句柄里读取尽可能多的数据。这个过程是伴随着子进程AOF落盘整个期间一直在进行，而并非是等到子进程完成AOF落盘完结后，由主进程进行收尾工作，一次性将累积的所有新数据追加到AOF文件尾部，因为此方案可能会长时间阻塞主进程对用户的实时响应。Redis作者在这里采用了“化整为零”的策略处理新数据的同步。
- 新文件生成后，必然涉及到文件改名以及`close()`旧文件等操作。
<br>Redis这里使用了`rename()`函数：

  >If oldname is not a directory, then any existing file named newname is removed during the renaming operation.<span style="color:red;">[4]</span>

  >If the link named by the new argument exists and the file's link count becomes 0 when it is removed and no process has the file open, the space occupied by the file shall be freed and the file shall no longer be accessible. If one or more processes have the file open when the last link is removed, the link shall be removed before rename() returns, but the removal of the file contents shall be postponed until all references to the file are closed.<span style="color:red;">[5]</span>
  
  此函数如果在处理引用计数为0的文件时，实际上触发删除旧文件的动作，而删除文件会引起阻塞当前进程。
  <br>Redis在这里采用了一个小技巧，当前进程先`open()`旧文件，使其引用计数>0，再执行`rename()`，这样旧文件不会因引用计数为0而触发删除操作。之后将先前open旧文件获得的句柄交由一个后台独立线程异步执行`close()`操作，这样至多只会阻塞后台独立线程而不会对核心主进程造成任何影响。

## 多进程的用途

多进程在Redis里主要用于数据持久化工作，利用`fork()`之后子进程内存数据是父进程的镜像这一原理。当然多数操作系统在实现`fork()`时均会采用cow技术以避免无必要的内存消耗。

进程之间的数据同步使用了无名管道`pipe()`,具体在之前的`数据持久化层面`章节有描述。

另外，父子进程之间信号机制用于控制对方动作。当有子进程在进行数据持久化时，父进程收到命令执行进程退出时，父进程自身退出前会发送SIGUSR1信号给子进程，通知子进程也要中止执行，避免子进程成为孤儿进程继续执行。

## 多线程的用途

在Redis里多线程主要用于执行辅助性的工作。当前Redis里共有3个后台工作线程，对应消费3个任务队列。主进程通过条件变量的同步机制，将3类任务分发到相应的任务队列里，工作线程从任务队列中取走任务执行，整理来看，是一个生产者-消费者模型。

3类任务如下
- 关闭文件句柄
  
  此类任务主要是专门处理`close()` Rewrite-AOF旧文件句柄，因为当关闭文件使其引用计数为0时会触发从磁盘上删除文件，这个阻塞操作需要异步执行。

- aof文件刷盘
  
  数据写入磁盘`write()`本质上是将数据写入内核缓冲区进行排队，等待系统周期性将数据正在的刷到磁盘上，当然系统也提供了`fdatasync()`函数供应用层主动刷盘以支持像数据库等对数据持久性敏感的业务场景。当然`fatasync()`必然是阻塞式的，会等待内核完成数据刷盘之后才会返回。Redis在RDB以及AOF数据持久化中，均会周期性的主动调用`fdatasync()`函数。

  那么本任务队列主要是承接AOF格式的刷盘动作。AOF的实现方式是将用户的新命令以文本格式追加写到AOF文件里，这里就会涉及到刷盘策略。在redis.conf配置文件中有一项设置aof的刷盘策略`appendfsync everyse`，当设置为`everysec`时，表示每秒主动刷盘一次，这一策略是性能与数据安全的折中，也是Redis官方推荐的默认策略。此策略的实现方式就是Redis主进程每秒提交一次刷盘任务到此队列，后台线程异步执行。注意：Rewrite-AOF过程的刷盘动作并未采用这种方式。

  写到这里，有人可能会问，RDB文件也是数据持久化，那么RDB数据刷盘动作在哪里执行的呢？之前提过，Redis对于数据持久化，无聊是RDB格式还是AOF格式里的Rewrite-AOF过程，都是采用`fork()`子进程独立进行数据持久化。既然已经有独立进程在后台进行数据持久化，那么就无需采用独立线程异步刷盘。其实Redis是在RDB子进程中，每写32MB数据执行一次同步刷盘动作，即使发生阻塞那么也仅仅阻塞了子进程数据持久化，主进程未受任何影响。

  进一步思考，AOF刷盘采用周期提交给后台工作线程异步执行，而Rewrite—AOF刷盘却是直接同步执行，为什么对AOF格式会有两种刷盘方式呢？笔者这里思考，这个设计应该时考虑到刷盘的优先级。AOF数据持久化是在主进程里进行，既要保证当前数据安全，又要避免阻塞后续流程，整个过程需要快速处理，所以即使是将刷盘动作提交到独立的后台线程异步执行，也要求后台执行尽可能的快速，避免无用的延误。所以这个相当于刷盘的快速通道，是高优先级，需要保证专用性。相比较而言，Rewrite-AOF的优先级就比较低了，即使本轮Rewrite-AOF失败，下一轮也会重新执行，不能将其刷盘动作跟高优先级的AOF刷盘动作混在一个通用队列里。

- 释放Redis自有object堆内存
  
  在实际运行中，总会遇到需要删除大容量的key-value键值对数据例如：set、sortedset、list等，可能单key里存有成千上万个节点数据，删除此类数据是个耗时工作，可能会阻塞主进程的执行。那么Redis就会采用标记删除的方式，将此key从集合中移除，但是value的内存释放工作交由本任务队列异步执行。


***参考资料***
1. UNIX Network Programming
2. https://redis.io/topics/persistence
3. dict字典里的安全迭代器与非安全迭代器的分析
4. http://www.gnu.org/software/libc/manual/html_mono/libc.html#Renaming-Files
5. https://linux.die.net/man/3/rename


