# 数据持久化机制

## 1. 基础技术介绍

类UNIX系统下，日常与文件操作相关的API大致分为两类：文件IO（File I/O）与标准IO库（Standard I/O Library）。

### 1.1 文件IO

文件IO是一种`无缓冲（unbuffered）`I/O，这个`无缓冲`的含义是相对于标准IO库而言。文件IO的API是直接调用内核里的系统函数，在API内部未引入缓冲区的设计。注意内核系统函数内部的缓冲区是内核层面的，与此处的`无缓冲`概念并无任何关联。

文件IO的使用特点是其API的操作对象是一个int型文件句柄，例如：`open()`、`read()`、`write()`、 `close()`、`lseek()` 等。

在文件IO范畴下，标准输入文件句柄0由`STDIN_FILENO`宏常量指代，标准输出文件句柄1由`STDOUT_FILENO`宏常量指代，标准错误文件句柄2由`STDERR_FILENO`宏常量指代。

### 1.2 标准IO库

标准IO库是由ISO C制定的标准库，在类UNIX系统已得到广泛的支持，是对文件IO的封装，内部引入缓冲区设计用于适配不同的内核文件块，以达到较优的性能，并对外提供编程友好的API。与文件IO相比，标准IO库是一种`缓冲（buffered）`I/O。

标准IO库的使用特点是围绕着一个`FILE *`结构体展开，例如：`fopen()`、`fgets()`、`fputs()`、`fread()`、`fwrite()`、`fclose()`等。

在标准IO库范畴下，标准输入`FILE *`由`stdin`宏常量指代，标准输出`FILE *`由`stdout`宏常量指代，标准错误`FILE *`由`stderr`宏常量指代。

在标准IO库引入了缓冲区设计的同时，还提供了是否开启缓冲区的API。目前支持三种缓冲模式
1. Fully Buffered全缓冲
2. Line Buffered行缓冲
3. Unbuffered无缓冲

通常情况下，`stderr`为无缓冲模式；当`stdin`与`stdout`跟终端相连时为行缓冲模式，其他情况则为全缓冲。

---

## 2. 本文术语说明
  
- 写盘

  调用`write()`，将数据由用户进程空间提交到内核缓冲区之后立刻返回，缓冲区里的数据等待内核稍后异步将数据真正的保存到磁盘上，这个过程就是延迟写（delayed write）。这个缓冲区的设计初衷是类UNIX系统内核提升文件系统的读写性能。

  这里稍微展开介绍一下`write()`在不同场景下的最终效果<span style="color:red;">[2]</span>。

  + 场景1 进程在`write()`成功返回后，进程崩溃或者被杀掉。

    已`write()`的数据不会丢失。因为这些数据已经在内核缓冲区里，进程退出(无论是正常exit还是异常中止)时，内核都会主动关闭进程已打开的文件句柄，通过延迟写机制后续将数据真正保存到磁盘上。

  + 进程在`write()`成功返回后，服务器断电。

    已`write()`的数据是否真正保存到磁盘结果未知。因为断电时，无法确保内核将内核缓冲区的数据安全的保存到磁盘上。

- 刷盘

  调用`fdatasync()`，用户层面主动通知内核将指定文件的缓存队列里的数据保存到磁盘上，数据保存完毕后才返回。此函数是阻塞式，可以确保数据真正保存到磁盘上。

- 落盘

  一个概括性术语，指代写数据到磁盘的整个过程，是写盘与刷盘的总称。

---

## 3. RDB

RDB猜测是`Redis DataBase`的缩写，是一种binary文件格式，记录Redis全量内存快照数据，供Redis数据持久化使用。

### 3.1 RDB格式

根据Redis所支持的自有数据结构，制定的一套二进制编码格式，可以将内存里的全量数据有组织的保存到文件里。

这套编码格式大致分为3类
- 常量编码
  
  主要包含自有数据类别，例如：list、hash、set、zset等。同时还定义了一组特殊的标记编码，用于记录内存里特别的数据，例如：定时失效标记、DB库id、LRU idle、字典里已用的桶个数、结束标记等。

- 字符编码
  
  字符编码是用于记录内存里的字符型数据，包括text字符以及binanry字符，一般而言，这类数据占Redis内存数据的大多数。
  
  整体格式为：
  |length字节数|data字符数据|
  |:-:|:-:|

  为了尽可能高效存储，这套字符编码对于`length字节数`细化了一组编码，以根据不同范围数值使用尽可能少的字节数。

  另外，对于`data字符数据`Redis作者也有针对性的进行了空间优化的设计，采用3种策略，每次都尽可能使用优先级高的策略记录数据。

  |优先级|保存策略|
  |:-:|:-:|
  |高|尝试将该字符型数据直接转为整型数据进行整型编码存储|
  |中|使用LZF压缩数据，至少需要节约4字节空间才认为ok|
  |低|原始格式存储|

  这里解释一下`高优先级`策略的优势，如果要保存的字符型数据内容为"100000"，字符串长度为6，至少需要1个字节记录length，所以如果直接采用字符型编码需要7个字节。而该数据可以转为整型100000，自身占用4字节，1个字节记录encode编码，使用整型编码需要5个字节，比字符型编码占用更少的空间。

- 整型编码
  
  顾名思义，只存储整型类别的数据，整体格式为：
  |encode编码|data整型数据|
  |:-:|:-:|

  当前整型编码只保存char、short、int型，至于64bit的long型则会走字符型编码流程进行存储。

### 1.2 RDB优点

- RDB是Redis内存全量数据的快照数据，另外其存储格式也很紧密，特别适合做历史数据备份归档使用。
- RDB文件很适合做灾备重建使用，单个二进制文件，且相比较AOF格式加载速度很快。
- 在RDB文件生成过程中，主进程除了fork创建子进程之外，全力响应用户的请求操作，性能发挥最大化。

### 1.3 RDB不足

- 数据安全性较差。因为RDB是全量快照数据，所以有一定的间隔周期，而在这些间隔时间如果进程异常，则会丢失该周期内的所有新数据。
- 内存消耗大。RDB文件是由主进程fork出来的子进程专职处理，尽管操作系统有cow技术以减少内存消耗，但是如果内存数据量巨大，子进程生成RDB文件必然持续较长时间，而此时如果主进程承接用户的新的写命令过多，必然导致内存短时膨胀，引起服务器内存紧张。

### 1.4 RDB配置参数

```shell

# 在子进程写RDB文件时，控制是否开启周期性主动刷盘。
# yes开启时，每写盘32MB数据之后会进行一次刷盘。
# no关闭时，整个保存RDB文件期间均不会主动刷盘，完全交由操作系统默认处理。
# 建议开启，否则在保存RDB文件结束时可能会导致大的延迟。
rdb-save-incremental-fsync yes

# RDB文件自动保存的触发条件
# 参数数据为： change_number second_period，表示在`second_period`有`change_number`以上变化时就自动开启RDB文件保存。
# 注意 参数中的计时周期`second_period`是以上一次成功完成rdb为准。
# 在上一次RDB保存成功的情况下,如下触发条件`任意一个`均可触发新的rdb保存。
# 在上一次RDB保存失败情况下,还需满足间隔5秒以上,才能考虑如下触发条件。
# 如果要关闭RDB持久化，可以设置 save ""
save 900 1
save 300 10
save 60 1000

# 在RDB文件生成的过程中如果发生错误,则Redis主进程是否执行用户的写请求
stop-writes-on-bgsave-error yes

# 是否开启RDB字符型数据压缩，以时间换空间，RDB文件占用更少空间
rdbcompression yes

# 是否开启RDB文件校验机制
# 在RDB文件末尾的结束符号后，会有固定的8字节空间存储校验码，如果关闭校验机制，则校验码以0保存且加载时不予校验。
rdbchecksum yes

# RDB文件名称
dbfilename dump.rdb

```
### 1.5 RDB持久化过程

相比于AOF的持久化，RDB持久化过程较为简单，因为RDB文件是快照数据，只需要完整记录某一时刻Redis内存全量数据即可，而在该时刻之后的内存数据更新，本次RDB文件不予包含，留待下次记录。这个机制可以充分利用类UNIX系统的父子进程共享内存原理，而且任意一方对内存的修改，均不会影响对方内存既有数据，即COW写时拷贝机制。

RDB持久化有两种触发方式，站在Redis进程的视角来看分为：被动触发与主动触发。
- 被动触发
  通过外部client发送命令，触发进行RDB文件生成。
  + `save`

    通知Redis server开启阻塞式生成RDB文件工作，由执行该命令的主进程将内存数据全量保存到RDB文件中，在此过程中阻塞其他所有client的命令执行以及Redis自身周期性任务，直至RDB文件生成完毕。

    一般在各类环境中均禁止使用此命令。

  + `bgsave`
  
    通知Redis server开启后台生成RDB文件工作，执行该命令的主进程在`fork()`一个子进程后，会继续处理其他client命令以及周期性任务，而子进程在后台将`fork()`发生这一时刻内存里的数据全量保存到文件里。

- 主动触发
  
  由Redis server自身根据配置文件中的`save`参数周期性的自动开启后台生成RDB文件工作，执行逻辑类似于`bgsave`命令。

这里我们只以`主动触发`引起的RDB文件生成过程为对象，介绍一下大致流程以及部分技术细节。

当Redis主进程通过周期性任务判定某一时间段内的变化次数已经超过配置的修改次数时，立即开启后台保存RDB工作，集群里的主备节点均会执行本逻辑。

这里稍微展开解释一下“某一时间段内的变化次数”是如何计算的。涉及到如下相关全局变量:
1. `server.dirty`  记录所有db库里累积变化次数；
2. `server.lastsave` 记录上一次RDB文件成功生成的秒级时间戳；
3. `server.dirty_before_bgsave` 在父子进程分叉执行之前备份`server.dirty`字段数值；
4. `server.lastbgsave_try` 记录最新一次执行后台保存RDB文件的任务开启时间戳；
5. `server.lastbgsave_status` 记录最新一次执行后台保存RDB文件的最终结果是正常or异常。

我们知道后台保存RDB文件的工作是由主进程`fork()`出来的子进程专职处理的，而主进程在`fork()`之后立即处理其他周期任务以及执行其他client的命令。其实此时主进程并不能将`server.dirty`归0以备重新计数，因为此时的子进程刚刚开始保存RDB文件，这个过程可能成功也可能异常终止，主进程的`server.dirty`提早归0无法应对子进程异常终止的场景。为此，引入了`server.dirty_before_bgsave`字段，此字段的作用就是在父子进程分叉执行之前，备份当时的`server.dirty`数值。同时Redis作者采用了一个非常灵活的方式解决何时重新计数的问题，在设置备份字段`server.dirty_before_bgsave`之后，主进程继续正常累积`server.dirty`数值，只有在主进程收到子进程正常结束RDB保存工作的信号通知时才会从`server.dirty`数值里刨除之前刚刚处理完毕的变化次数即`server.dirty_before_bgsave`数值，这样就避免了重复计数。而如果子进程保存失败，主进程对`server.dirty`不做任何刨除操作，从而确保了计数的准确性。`server.lastbgsave_try`与`server.lastbgsave_status`是为了应对子进程保存失败的场景制定的特别策略：最近一次保存失败的5秒内不允许开启新的后台RDB保存任务，给服务器`喘息`机会，避免陷入高频`出错-重执行`的低效循环。

RDB文件完结时子进程会通知父进程已经保存完毕，父子进程采用的通信方式有两种：
1. `pipe()`
   
   父进程在创建子进程之前，会创建一个无名管道`server.child_info_pipe`，子进程在完结时会将自身一些信息通过该管道发送给父进程。这里面会包含哪些信息呢？我们知道RDB文件的生成工作是由`fork()`出来子进程进行，COW机制会使父子进程共享一份“读内存”，后续任何一方对该内存页的“写操作”会导致内核为此拷贝一份供修改，理论上在RDB文件生成的这个阶段，父子进程应该尽可能少的修改内存数据，以减少内存页拷贝。那么这期间涉及`COW`的内存量就是比较关键信息，也就是子进程通过管道发送给父进程的运行信息。`COW`的内存量是子进程读取`/proc/self/smaps`文件，获取其中的Private_Dirty字段的数值<span style="color:red;">[3]</span>。

   这里同样也涉及到另一个潜在问题，RDB子进程向管道`write()`数据后自身立即`exit()`，父进程还未从管道中`read()`，这时处在管道中的待读数据会发生什么呢？

   >If a process attempts to read from an empty pipe, then read(2) will block until data is available.  If a process attempts to write to a full pipe (see below), then write(2) blocks until sufficient data has been read from the pipe to allow the write to complete.  Nonblocking I/O is possible by using the fcntl(2) F_SETFL operation to enable the O_NONBLOCK open file status flag. <p>The communication channel provided by a pipe is a byte stream: there is no concept of message boundaries.<p>If all file descriptors referring to the write end of a pipe have been closed, then an attempt to read(2) from the pipe will see end-of-file (read(2) will return 0).  If all file descriptors referring to the read end of a pipe have been closed, then a write(2) will cause a SIGPIPE signal to be generated for the calling process.  If the calling process is ignoring this signal, then write(2) fails with the error EPIPE.  An application that uses pipe(2) and fork(2) should use suitable close(2) calls to close unnecessary duplicate file descriptors; this ensures that end-of-file and SIGPIPE/EPIPE are delivered when appropriate<span style="color:red;">[4]</span>.

   >If we read from a pipe whose write end has been closed, read returns 0 to indicate an end of file after all the data has been read. (Technically, we should say that this end of file is not generated until there are no more writers for the pipe. It’s possible to duplicate a pipe descriptor so that multiple processes have the pipe open for writing. Normally, however, there is a single reader and a single writer for a pipe. When we get to FIFOs in the next section, we’ll see that often there are multiple writers for a single FIFO.)<span style="color:red;">[5]</span>

   >This should make it obvious why pipe() creates two file descriptors. The writer writes all the data it needs into the write fd and closes the fd. This also triggers an EOF to be sent. The reader would usually keep reading data until it encounters the EOF and closes its end. In this scenario, there's a period of time where the write fd is closed but data is still buffered in the pipe, waiting to be read out by the reader<span style="color:red;">[6]</span>. 

   上述3处解释可以确认：
   1. 只有当父子进程关闭各自的“pipe写侧fd[1]”时才会触发EOF标记；
   2. 阻塞模式下，当管道中无数据时，“pipe读侧fd[0]”的读取会阻塞当前调用进程，直至有数据or碰到EOF；
   3. 非阻塞模式下，无论什么场景下均不会阻塞“pipe读侧fd[0]”的读取进程。
   
   在父子进程均没有`close`各自无用的pipe文件句柄的情况下，子进程先`exit()`，那么处于管道中待读取的数据依旧有效，父进程依旧可以`read()`。

   当父进程关闭“写侧fd[1]”且子进程关闭“读侧fd[0]”，而管道中还有未读取的数据时子进程已经`exit()`，父进程是否能从管道中读到这些数据呢？按照《APUE》的解释，是可以读到这些数据，并且末尾会看到EOF。

   Redis作者目前采用的如下方式确保管道中的数据不丢失：
   1. 父子进程均没有关闭各自无用的pipe句柄，即子进程退出时不会有EOF；
   2. 将`读侧`设置为Non-Block，确保当管道中无数据时不会阻塞`读进程`；
   3. 不以EOF标记作为结束依据，通信数据以定长结构体封装，读取成功的依据只判断读到的数据长度是否为定长。

2. `wait3()`

   父进程周期性调用`wait3()`尝试获得子进程的退出状态，在避免僵尸子进程一直占用资源的同时，也可以由父进程处理一些RDB收尾工作，例如：server.dirty中对server.dirty_before_bgsave的刨除，RDB状态字段的回置等。因为`wait3()`是由父进程周期性调用，为避免阻塞式等待子进程完结，所以代码里使用了`WNOHANG`选项。

### 1.6 RDB的`write`写盘与`fdatasync`刷盘逻辑

RDB文件是快照数据，不需要实时保存用户的新数据，并且持久化工作是由单独子进程专职处理，所以写盘与刷盘操作逻辑较为简单。在该方面用户可以调整的配置参数只有`rdb-save-incremental-fsync`。`yes`表示子进程会每写盘32MB数据之后主动进行一次刷盘动作。`no`表示子进程只会在`close()`文件之前做一次主动刷盘，除此之外再无主动刷盘，全部由操作系统来处理刷盘逻辑。建议设置为`yes`，采用渐进式的主动刷盘，避免在最终刷盘可能引起较大的延时。

---

## 2. AOF

AOF是`Append Only File`的缩写，是一种text文件格式。该格式文件记录的是原始操作命令，加载时重放文件内容以重建内存全量数据。

### 2.1 AOF格式

text格式，可实时记录用户原始的RESP格式<span style="color:red;">[7]</span>的操作命令。

### 2.2 AOF优点

- 因AOF是实时记录用户命令，数据持久化更加健壮，更可以根据业务场景倾向于高性能还是数据安全，来针对性的设置不同的刷盘策略。
- AOF文件只追加数据并不涉及过往命令的修改，所以io性能是符合要求。如遇断电等极端异常，“数据半写”情况也仅涉及最后一条命令，`redis-check-aof`工具可进行移除修复。
- AOF文件以文本方式记录用户的写命令，在某种程度上相当于操作日志，运维操作更加便捷。

### 2.3 AOF不足

- 相比于RDB，存储同量数据情况下AOF文件的磁盘空间消耗更大。
- AOF文件大小会随着操作频率逐日变大，而过大的AOF文件又会降低Redis重启时的回放效率。不过Redis支持自动Rewrite-AOF机制，使用RESP命令记录内存里的数据，同时旧的AOF文件也并行记录用户的新数据，保证在此期间不丢数据。
- AOF的性能受刷盘策略有很大影响，默认策略是“每秒刷盘”性能较高，“不主动刷盘”的策略下保存性能与RDB格式相当，“每次刷盘”策略性能较差，却是最少可能丢数据。

### 2.4 AOF配置参数
```shell
# 是否开启AOF持久化数据功能
# 注意：即使关闭AOF持久化功能，用户可以使用`bgrewriteaof`命令触发Redis server进行一次AOF文件落地。
appendonly no

# AOF文件名称
appendfilename "appendonly.aof"

# AOF刷盘策略，默认策略是"everysec"每秒刷盘。同时也支持"always"每次刷盘；"no"不主动刷盘。
appendfsync everysec

# 在后台子进程正在进行写RDB or Rewrite-AOF期间，无论AOF刷盘策略配置成everysec还是always，是否暂停主进程里的AOF文件主动刷盘。
no-appendfsync-on-rewrite no

# 自动触发Rewrite-AOF的阈值：当前AOF文件的大小对比最近一次Rewrite-AOF文件大小的百分比
auto-aof-rewrite-percentage 100
# 自动触发Rewrite-AOF的阈值：自动进行Rewrite-AOF的最小AOF文件大小，以避免AOF文件很小时频繁进行Rewrite-AOF。
auto-aof-rewrite-min-size 64m

# 当Redis基于AOF文件重启时发现文件中最后一条命令不完整时，进程是自动忽略该条命令[yes] 还是 中止运行[no]
# 注意：如果发现该不完整命令并不是文件中最后一条时，进程中止运行。即本配置参数只对最后一条命令有效。
aof-load-truncated yes

# 在子进程Rewrite-AOF时，控制是否开启周期性主动刷盘。
# yes开启时，每写盘32MB数据之后会进行一次刷盘。
# no关闭时，整个Rewrite期间均不会主动刷盘，完全交由操作系统默认处理。
# 建议开启，否则在写文件结束时可能会导致大的延迟。
aof-rewrite-incremental-fsync yes
```

### 2.5 Rewrite-AOF

AOF格式是对文件追加用户最新的命令，那么文件会越来越大，必然会拖慢Redis重启回放AOF文件的速度。因此，Redis支持对AOF文件进行重建，以RESP格式保存内存里的最新数据，并在此期间依旧可以正常执行并保存外部用户的新命令。

#### 2.5.1 开启方式

- 被动方式

  用户通过API接口发送`bgrewriteaof`命令，Redis server无阻塞式的开启Rewrite-AOF过程。当然用户是无法通过接口获得Rewrite-AOF的执行终态结果，只能受到表示是否开启Rewrite的结果。

- 主动方式

  Redis server可以根据自身运行情况以决定是否自动开启Rewrite-AOF过程，无需外部命令介入。可以通过如下配置参数决定是否开启以及何时开启主动Rewrite-AOF。

  1. appendonly 是否开启AOF功能
  2. auto-aof-rewrite-percentage 自动Rewrite-AOF阈值：依据AOF文件大小的增加百分比
  3. auto-aof-rewrite-min-size 自动Rewrite-AOF阈值：最低AOF文件大小

#### 2.5.2 Rewrite-AOF过程

Rewrite-AOF过程也是主要用的`fork()`子进程将内存快照数据保存到新的AOF文件里，但是因为AOF文件是需要实时记录用户的新命令，所以在Rewrite-AOF过程中还需要将增量命令数据同步保存到新AOF文件里。整体过程大致分3部分：`fork()`子进程保存快照数据；主进程周期性同步增量命令给子进程；子进程完结以及主进程进行的收尾工作。我们在这里展开说明一下。

- Rewrite-AOF保存现有内存数据：`fork()`子进程保存快照数据
    
  在符合一定的前提条件后，主进程准备开启Rewrite-AOF过程。与RDB保存过程类似，由主进程`fork()`的子进程专职保存内存里的既有数据，只不过Rewrite-AOF过程里是以AOF格式保存。与此同时，主进程并行处理原有的既定任务，例如执行client新命令并将其保存到现有的AOF文件中；周期性的其他任务等。

  这里特别说明一下，在子进程保存自身内存数据的同时，主进程仍然需要正常进行数据持久化，即在Rewrite期间，主进程保存新命令到原有AOF文件，而子进程保存内存快照数据到新AOF文件里，可想而知此时有两份文件正在进行写操作。为减少对磁盘的冲击，Redis作者提供了一个配置参数`no-appendfsync-on-rewrite`，控制在后台子进程保存数据时，是否暂停主进程里的主动刷盘`fdatasync`操作。配置为`yes`时，Redis主进程对AOF文件正常写盘但是暂停刷盘，将相关资源向子进程倾斜，优先保证子进程写操作尽快完成。不过此时会让原有的AOF数据健壮性较差，如遇到断电等突发故障会导致部分数据丢失，某些系统下可能会有30秒左右的数据丢失。建议只在遇到有明显延迟现象时，才设置为`yes`，一般默认情况下设置为`no`。

- Rewrite-AOF过程中同步增量命令：父进程周期性同步增量命令给子进程

  AOF格式的特点就是实时保存用户的操作命令。在进行Rewrite-AOF过程中，主进程将执行成功的新命令写入原有的AOF文件，那么这些新命令如何保存到新的AOF文件中呢？在讲解Redis采用的方案之前，我们自己不妨先思考一下有哪些措施？
  1. 主进程存
   
     子进程不保存任何增量命令，全权由主进程记录增量命令。待子进程完结后，主进程将累积的所有增量命令保存到新AOF文件中。

     优点：实现简单，各进程之间无需数据通信。
     缺点：如果累积了大量的增量数据，那么主进程会耗费较长时间在此处，必然会阻塞了其他任务的执行，影响Redis性能。

  2. 子进程存
   
     子进程负责增量命令保存。在主进程将增量命令同步给子进程之后，子进程将其保存到新AOF文件中。

     优点：不会长时间阻塞主进程，性能影响较小。
     缺点：实现复杂，需要处理大量的进程间数据交互工作。
  
  Redis选择了第二种对性能更加友好的方案。如下我们分析一下Redis的具体实现细节。
  + 主进程侧
    
    主进程使用`块链`累积增量数据，并周期性的同步给子进程。
    
    * 内存存储方式
    ```c
    #define AOF_RW_BUF_BLOCK_SIZE (1024*1024*10)    /* 10 MB per block */

    typedef struct aofrwblock {
      unsigned long used, free;
      char buf[AOF_RW_BUF_BLOCK_SIZE];
    } aofrwblock;
    ```

    该`块链`结构专门存储大量的不定长数据，以该结构体作为`value`存到`list`链表中，整体形成`块链`，实际数据被分割有序保存到该链表中。主进程在成功执行新的用户命令并存入原有AOF文件之后，会将同一份命令存入此`块链`的最后一块中，如只能保存部分命令数据，则主进程从内核申请`8+8+10M`堆内存，将剩余数据存入该块，如此循环直至将命令数据全部分割存储完毕。

    * 发送方式

    主进程会在`fork()`子进程之前，使用`pipe()`创建3组无名管道共6个文件句柄，作用如下

    |组别|文件句柄名|阻塞类别|读/写|通道类别|说明|
    |:-:|:-:|:-:|:-:|:-:|:-:|
    |1|server.aof_pipe_write_data_to_child|Non-Block|write|数据|主->子，发送增量数据|
    |1|server.aof_pipe_read_data_from_parent|Non-Block|read|数据|子<-主，接收增量数据|
    |2|server.aof_pipe_write_ack_to_parent|Block|write|控制|子->主，发送期望结束符号'!'<p>期望主进程中止发送增量数据|
    |2|server.aof_pipe_read_ack_from_child|Block|read|控制|主<-子，接收期望结束符号'!'|
    |3|server.aof_pipe_write_ack_to_child|Block|write|控制|主->子，发送确认结束符号'!'<p>主进程确认中止|
    |3|server.aof_pipe_read_ack_from_parent|Block|read|控制|子<-主，接收确认结束符号'!'| 

    主进程每次将增量命令分割存储到`块链`之后，都会在核心事件分配器上注册`server.aof_pipe_write_data_to_child`句柄的异步写事件。当`server.aof_pipe_write_data_to_child`句柄可写时，则从头遍历`块链`，按照节点顺序将`aofrwblock.buf`里的数据写入`server.aof_pipe_write_data_to_child`句柄，每写完一个节点的数据就直接从链表中删除该节点，直至[写入失败]or[块链为空]才中止。
    
    如果`块链`数据很多，主进程每次发送尽可能多的`块链`数据会不会引起阻塞呢？应该不会的，作者使用两个措施以避免引起长阻塞：
    1.  上述句柄都是无名管道的“两端”，而无名管道的内核缓冲区是上限值。
    >A pipe has a limited capacity.  If the pipe is full, then a write(2) will block or fail, depending on whether the O_NONBLOCK flag is set.
    >In Linux versions before 2.6.11, the capacity of a pipe was the same as the system page size (e.g., 4096 bytes on i386).  Since Linux2.6.11, the pipe capacity is 16 pages (i.e., 65,536 bytes in a system with a page size of 4096 bytes).<span style="color:red;">[4]</span> 

    2.  用于发送/接收增量数据的管道句柄均是非阻塞模式。

  + 子进程侧

    子进程周期性的接收主进程发来的增量数据，并按序暂存在自身进程内存中，待子进程将快照内存全量Rewrite到新AOF文件之后，在把暂存的数据追加到新AOF文件的尾部。

    * 内存存储方式

      子进程使用`server.aof_child_diff`变量存储主进程发来的增量数据，该变量类型为sds，即字符数组。子进程每收到新数据后，均会调用`sdscatlen`追加到尾部。
      
      子进程需要一直在内存里持有`server.aof_child_diff`数据，直至内存快照数据全量写入新的AOF文件后，才会将`server.aof_child_diff`的数据追加到文件的尾部。

      注意子进程这里并未使用主进程用到的`块链`内存结构，原因未知。。。

    * 接收方式 

      既然增量数据是周期性发送的，所以子进程必然需要周期性接收才行。而子进程都是一直处理内存快照数据写入新AOF文件，那么这个周期性接收工作在哪个环节执行呢？Redis作者为此设置了一个游标变量，该游标是跟踪内存快照写入文件的字节数，每写超过10K字节，子进程就中途调用一下接收函数。该接收函数每次接收尽可能多的增量数据，直至异常才会中止本轮接收。为避免引起阻塞，该接收函数所操作的句柄`server.aof_pipe_read_data_from_parent`设置为非阻塞式，而且每次read最多65536字节，这个也是针对`pipe`内核缓冲区大小所设定的。
  
- Rewrite-AOF结束：子进程完结以及主进程处理收尾工作

  子进程将内存快照数据全量写入AOF文件之后，就需要着手处理自身的收尾工作：如何保存已接收的增量命令以及通知主进程等事项。此时主进程与子进程是并行运行，而增量命令间歇性的从主进程流向子进程。内存`COW`机制导致的内存消耗以及两份磁盘io消耗，需要子进程尽快完结。无名管道缓冲区里的数据如何优雅的接收干净，这里需要有一个清晰的数据边界，确保双方无遗漏任何数据。为此Redis作者使用了2组`pipe`作为控制通道使用：1) 子进程期望主进程中止发送；2) 主进程确认中止发送。这两步使用的控制符号是'!'，主进程一旦从`server.aof_pipe_read_ack_from_child`句柄中收到此符号，便会从核心事件分配器中注销之前的`server.aof_pipe_write_data_to_child`句柄写事件，并将`server.aof_stop_sending_diff`标记字段置为1。这里已经注销了发送增量数据的写事件，为什么还需要记录一个标记字段呢？这里我们需要从核心事件分配器的角度来分析，主进程在核心事件分配器里注册了2个异步事件：
  |句柄|读/写|用途|
  |:-:|:-:|:-:|
  |server.aof_pipe_read_ack_from_child|read|主进程接收期望结束符号'!'|
  |server.aof_pipe_write_data_to_child|write|主进程发送增量数据|

  上述两个异步事件在执行时并无先后顺序之分，完全由

### 2.6 AOF持久化过程

### 2.7 AOF的`write`写盘与`fdatasync`刷盘逻辑


---
## 3. RDB与AOF组合使用

---

***参考资料***
1. https://redis.io/topics/persistence
2. http://oldblog.antirez.com/post/redis-persistence-demystified.html
3. https://unix.stackexchange.com/questions/33381/getting-information-about-a-process-memory-usage-from-proc-pid-smaps
4. http://man7.org/linux/man-pages/man7/pipe.7.html
5. APUE
6. https://stackoverflow.com/questions/22032120/closing-pipe-file-descriptor-in-c
7. https://redis.io/topics/protocol